{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioAuditore/TDA-for-Travelling-Salesman/blob/main/train_tsp_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDiSVtV4AtV8"
      },
      "source": [
        "## Based on \"The Transformer Network for the Traveling Salesman Problem\"\n",
        "\n",
        "Xavier Bresson, Thomas Laurent, Feb 2021<br>\n",
        "\n",
        "Arxiv : https://arxiv.org/pdf/2103.03012.pdf<br>\n",
        "Talk : https://ipam.wistia.com/medias/0jrweluovs<br>\n",
        "Slides : https://t.co/ySxGiKtQL5<br>\n",
        "\n",
        "This code trains the transformer network by reinforcement learning.<br>\n",
        "Use the beam search code to test the trained network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k7_6HjsGAtWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8994bb7b-e454-4ab0-a67c-5125cb7927aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TDA-for-Travelling-Salesman'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 95 (delta 9), reused 0 (delta 0), pack-reused 72\u001b[K\n",
            "Receiving objects: 100% (95/95), 104.56 MiB | 26.23 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "Updating files: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MarioAuditore/TDA-for-Travelling-Salesman.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UoYl94oOAtWB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/TDA-for-Travelling-Salesman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-n8RGLEKAtWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac732fa-5ace-47ba-91fe-09112e9590b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyconcorde@ git+https://github.com/jvkersch/pyconcorde\n",
            "  Cloning https://github.com/jvkersch/pyconcorde to /tmp/pip-install-ymfuinz6/pyconcorde_cfdb5e4ed805429bb905f7627b525036\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jvkersch/pyconcorde /tmp/pip-install-ymfuinz6/pyconcorde_cfdb5e4ed805429bb905f7627b525036\n",
            "  Resolved https://github.com/jvkersch/pyconcorde to commit 8a6b193b79ebdf8f07e0b0635722b3b4edbc1560\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (1.25.2)\n",
            "Collecting tsplib95 (from pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading tsplib95-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (8.1.7)\n",
            "Collecting Deprecated~=1.2.9 (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting networkx~=2.1 (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate~=0.8.7 (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated~=1.2.9->tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (1.14.1)\n",
            "Building wheels for collected packages: pyconcorde\n",
            "  Building wheel for pyconcorde (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyconcorde: filename=pyconcorde-0.1.0-cp310-cp310-linux_x86_64.whl size=2576441 sha256=b5421c92031459d934a341e8f2065781add0132cabc3200e4a398f87d0377ad0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1y9f4n55/wheels/be/9f/eb/e4f95e06e62f057a045679e4940e536d1b251d1ab4859c6dcc\n",
            "Successfully built pyconcorde\n",
            "Installing collected packages: tabulate, networkx, Deprecated, tsplib95, pyconcorde\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.9.0\n",
            "    Uninstalling tabulate-0.9.0:\n",
            "      Successfully uninstalled tabulate-0.9.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "bigframes 0.24.0 requires tabulate>=0.9, but you have tabulate 0.8.10 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 networkx-2.8.8 pyconcorde-0.1.0 tabulate-0.8.10 tsplib95-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install 'pyconcorde @ git+https://github.com/jvkersch/pyconcorde'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install giotto-ph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpz8V14yEkU9",
        "outputId": "16e17d30-5f82-42e3-a831-d79fe2fb8752"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting giotto-ph\n",
            "  Downloading giotto_ph-0.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.4/526.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from giotto-ph) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from giotto-ph) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from giotto-ph) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->giotto-ph) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.1->giotto-ph) (3.3.0)\n",
            "Installing collected packages: giotto-ph\n",
            "Successfully installed giotto-ph-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hGW4PaR3AtWC"
      },
      "outputs": [],
      "source": [
        "# ================\n",
        "# Libs\n",
        "# ================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import gph\n",
        "\n",
        "# Models\n",
        "from tsp_transformer.model import TSP_net, compute_tour_length\n",
        "\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "# visualization\n",
        "%matplotlib inline\n",
        "# from IPython.display import set_matplotlib_formats, clear_output\n",
        "# set_matplotlib_formats('png2x','pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from concorde.tsp import TSPSolver # !pip install -e pyconcorde\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LPdggSO0AtWC",
        "outputId": "2d1d510d-159f-4170-9a35-5afc70ae177f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU name: Tesla T4, gpu_id: 0\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Hardware : CPU / GPU(s)\n",
        "###################\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    gpu_id = '0'\n",
        "    device = torch.device(\"mps\")\n",
        "\n",
        "elif torch.cuda.is_available():\n",
        "    gpu_id = '0' # select a single GPU\n",
        "    # gpu_id = '2,3' # select multiple GPUs\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))\n",
        "\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    gpu_id = -1 # select CPU\n",
        "\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PFvE_qMOAtWD",
        "outputId": "52ebfc91-5c20-4e73-cae0-4f6c59326c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu_id': '0', 'nb_nodes': 10, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 4, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 20, 'batch_size': 128, 'nb_batch_per_epoch': 250, 'nb_batch_eval': 100, 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n"
          ]
        }
      ],
      "source": [
        "# ================\n",
        "# Hyper-parameters\n",
        "# ================\n",
        "\n",
        "class DotDict(dict):\n",
        "    def __init__(self, **kwds):\n",
        "        self.update(kwds)\n",
        "        self.__dict__ = self\n",
        "\n",
        "args = DotDict()\n",
        "args.gpu_id = gpu_id\n",
        "\n",
        "# TSP problem number of nodes\n",
        "args.nb_nodes = 10 # TSP10\n",
        "# args.nb_nodes = 20 # TSP20\n",
        "\n",
        "# Transformer parameters\n",
        "args.dim_emb = 128 # dimension of embeddings in transformer\n",
        "args.dim_ff = 512 # dimension of feed forward layers\n",
        "args.dim_input_nodes = 4 #2 # dimension of input features\n",
        "args.nb_layers_encoder = 6\n",
        "args.nb_layers_decoder = 2\n",
        "args.nb_heads = 8\n",
        "\n",
        "#\n",
        "args.nb_epochs = 20 # number of epochs\n",
        "args.batch_size = 128 # batch size\n",
        "args.nb_batch_per_epoch = 250 # number of batches to generate on each epoch for training\n",
        "args.nb_batch_eval = 100 # number of batches to generate on each epoch for evaluation\n",
        "args.lr = 1e-4 # optimiser lr\n",
        "args.tol = 1e-3 # model should perform better w.r.t tolerance to be updated\n",
        "args.batchnorm = True  # if batchnorm=True  than batch norm is used\n",
        "# args.batchnorm = False # if batchnorm=False than layer norm is used\n",
        "args.max_len_PE = 1000\n",
        "\n",
        "print(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmojlcwlAtWD"
      },
      "source": [
        "# Training\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A2JoNUSvAtWE",
        "outputId": "fc952d88-3a3d-46ab-e8d7-cf28b2e564f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu_id': '0', 'nb_nodes': 10, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 4, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 20, 'batch_size': 128, 'nb_batch_per_epoch': 250, 'nb_batch_eval': 100, 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Instantiate a training network and a baseline network\n",
        "###################\n",
        "try:\n",
        "    del model_train # remove existing model\n",
        "    del model_baseline # remove existing model\n",
        "except:\n",
        "    pass\n",
        "\n",
        "model_train = TSP_net(args.dim_input_nodes,\n",
        "                      args.dim_emb,\n",
        "                      args.dim_ff,\n",
        "                      args.nb_layers_encoder,\n",
        "                      args.nb_layers_decoder,\n",
        "                      args.nb_heads,\n",
        "                      args.max_len_PE,\n",
        "                      batchnorm=args.batchnorm)\n",
        "\n",
        "model_baseline = TSP_net(args.dim_input_nodes,\n",
        "                         args.dim_emb,\n",
        "                         args.dim_ff,\n",
        "                         args.nb_layers_encoder,\n",
        "                         args.nb_layers_decoder,\n",
        "                         args.nb_heads,\n",
        "                         args.max_len_PE,\n",
        "                         batchnorm=args.batchnorm)\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(torch.cuda.device_count() + \" cuda devices found, doing parallel training.\")\n",
        "    model_train = nn.DataParallel(model_train)\n",
        "    model_baseline = nn.DataParallel(model_baseline)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_train.parameters(), lr = args.lr)\n",
        "\n",
        "model_train = model_train.to(device)\n",
        "model_baseline = model_baseline.to(device)\n",
        "model_baseline.eval()\n",
        "\n",
        "print(args); print('')\n",
        "\n",
        "# Logs\n",
        "os.system(\"mkdir logs\")\n",
        "time_stamp=datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n",
        "file_name = 'logs'+'/'+time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id) + \".txt\"\n",
        "file = open(file_name,\"w\",1)\n",
        "file.write(time_stamp+'\\n\\n')\n",
        "for arg in vars(args):\n",
        "    file.write(arg)\n",
        "    hyper_param_val=\"={}\".format(getattr(args, arg))\n",
        "    file.write(hyper_param_val)\n",
        "    file.write('\\n')\n",
        "file.write('\\n\\n')\n",
        "plot_performance_train = []\n",
        "plot_performance_baseline = []\n",
        "all_strings = []\n",
        "epoch_ckpt = 0\n",
        "tot_time_ckpt = 0\n",
        "\n",
        "\n",
        "# # Uncomment these lines to re-start training with saved checkpoint\n",
        "# ====================================================================\n",
        "# checkpoint_file = \"checkpoint/checkpoint_21-03-01--17-25-00-n50-gpu0.pkl\"\n",
        "# checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "# epoch_ckpt = checkpoint['epoch'] + 1\n",
        "# tot_time_ckpt = checkpoint['tot_time']\n",
        "# plot_performance_train = checkpoint['plot_performance_train']\n",
        "# plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
        "# model_baseline.load_state_dict(checkpoint['model_baseline'])\n",
        "# model_train.load_state_dict(checkpoint['model_train'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "# print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
        "# del checkpoint\n",
        "# ====================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3MLpLoMAtWE"
      },
      "source": [
        "## Test\n",
        "### Best solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oX41tczIAtWE"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "create_checkpoint = False\n",
        "test_size = 1000\n",
        "n_nodes = args.nb_nodes\n",
        "\n",
        "if create_checkpoint:\n",
        "    x = torch.rand(test_size, n_nodes, args.dim_input_nodes, device='cpu')\n",
        "\n",
        "    def best_path(points):\n",
        "        solution = TSPSolver.from_data(points[:, 0], points[:, 1], norm='GEO').solve(verbose=False)\n",
        "        return compute_tour_length(points[None, :], solution.tour[None, :]).to('cpu')\n",
        "\n",
        "    lengths = Parallel(n_jobs=-1)(delayed(best_path)(points) for points in x)\n",
        "\n",
        "    best_length_mean = torch.tensor(lengths).mean()\n",
        "\n",
        "    data_dir = os.path.join(\"data\")\n",
        "    torch.save({ 'x': x, 'mean': best_length_mean}, '{}.pkl'.format(data_dir + f\"/{test_size}tsp{n_nodes}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NY37m7sAtWE"
      },
      "source": [
        "### TSP tasks as validation checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2oGjtQZ9AtWE",
        "outputId": "e43aee9e-f9ea-4424-c2ea-063b32925a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb of nodes : 10 | mean length: 2.882951259613037\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Small test set for quick algorithm comparison\n",
        "# Note : this can be removed\n",
        "###################\n",
        "\n",
        "checkpoint = None\n",
        "\n",
        "if args.nb_nodes==10 : checkpoint = torch.load(\"data/1000tsp10.pkl\")\n",
        "if args.nb_nodes==20 : checkpoint = torch.load(\"data/1000tsp20.pkl\")\n",
        "\n",
        "if checkpoint is not None:\n",
        "    x_test_tsp = checkpoint['x']\n",
        "    x_test_len = checkpoint['mean']\n",
        "    n = x_test_tsp.size(1)\n",
        "    print(f'nb of nodes : {n} | mean length: {x_test_len}')\n",
        "else:\n",
        "    x_test_tsp = torch.rand(test_size, args.nb_nodes, args.dim_input_nodes, device='cpu')\n",
        "    x_test_len = 1e-7\n",
        "    n = x_test_tsp.size(1)\n",
        "    print('nb of nodes :',n)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TDA"
      ],
      "metadata": {
        "id": "agreLCTXEp4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_homology(points):\n",
        "    # Calculate homology using ripser_parallel\n",
        "    output = gph.ripser_parallel(points, return_generators=True)\n",
        "\n",
        "    # Initialize arrays for H0_birth, H0_death, H1_birth, and H1_death\n",
        "    num_points = points.shape[0]\n",
        "    # H0_birth, H0_death = np.zeros(num_points, dtype=int), np.zeros(num_points, dtype=int)\n",
        "    H1_birth, H1_death = np.zeros(num_points, dtype=int), np.zeros(num_points, dtype=int)\n",
        "\n",
        "    # Iterate over finite generators for H0\n",
        "    # for i in range(len(output['gens'][0])):\n",
        "    #     birth_vertex = output['gens'][0][i][0]\n",
        "    #     death_vertices = output['gens'][0][i][1:]\n",
        "\n",
        "    #     H0_birth[birth_vertex] = 1\n",
        "    #     H0_death[death_vertices] = 1\n",
        "\n",
        "    # Iterate over infinite generators for H0\n",
        "    # for i in range(len(output['gens'][2])):\n",
        "    #     birth_vertex = output['gens'][2][i]\n",
        "\n",
        "    #     H0_birth[birth_vertex] = 1\n",
        "\n",
        "    # Iterate over finite generators for H1\n",
        "    for i in range(len(output['gens'][1][0][:2])):\n",
        "        birth_vertices = output['gens'][1][0][i][:2]\n",
        "        death_vertices = output['gens'][1][0][i][2:]\n",
        "\n",
        "        H1_birth[birth_vertices] = 1\n",
        "        H1_death[death_vertices] = 1\n",
        "\n",
        "    # Iterate over infinite generators for H1\n",
        "    for i in range(len(output['gens'][3])):\n",
        "        birth_vertices = output['gens'][3][i]\n",
        "        if birth_vertices.size > 0:\n",
        "            H1_birth[birth_vertices] = 1\n",
        "\n",
        "    return np.column_stack((points[:,0], points[:,1], H1_birth, H1_death))\n",
        "\n",
        "# Example usage:\n",
        "# points = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n",
        "# H0_birth, H0_death, H1_birth, H1_death = calculate_homology(points)"
      ],
      "metadata": {
        "id": "yb4fyXN3Epqi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j_vGgpMAtWF"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "scrolled": true,
        "id": "zc7B1ys8AtWF",
        "outputId": "08f37400-ea99-412d-c317-3bf5081b7b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 1/20 [01:18<24:46, 78.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, epoch time: 0.968min, tot time: 0.001day, L_train: 7.782, L_base: 7.777, L_test: 3.043, gap_train(%): 5.562, update: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [01:55<36:25, 115.03s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7cbb08b7e5f3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# new_f = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# data = x # np.concat(x, new_f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_homology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# compute tours for model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "###### ==================\n",
        "# Main training loop\n",
        "# ==================\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "start_training_time = time.time()\n",
        "\n",
        "for epoch in tqdm(range(0, args.nb_epochs)):\n",
        "\n",
        "    # re-start training with saved checkpoint\n",
        "    # epoch += epoch_ckpt\n",
        "\n",
        "    # -------------------------\n",
        "    # Train model for one epoch\n",
        "    # -------------------------\n",
        "    start = time.time()\n",
        "    model_train.train()\n",
        "\n",
        "    for step in range(1, args.nb_batch_per_epoch + 1):\n",
        "\n",
        "        # generate a batch of random TSP instances\n",
        "        x = torch.rand(args.batch_size, args.nb_nodes, args.dim_input_nodes) # size(x)=(batch_size, nb_nodes, dim_input_nodes)\n",
        "\n",
        "        # generate topological features\n",
        "        # new_f = ...\n",
        "        # data = x # np.concat(x, new_f)\n",
        "        data = torch.tensor(Parallel(n_jobs=-1)(delayed(calculate_homology)(i) for i in x), dtype=torch.float32)\n",
        "\n",
        "        # compute tours for model\n",
        "        tour_train, sumLogProbOfActions = model_train(data.to(device), deterministic=False) # size(tour_train)=(batch_size, nb_nodes), size(sumLogProbOfActions)=(batch_size)\n",
        "\n",
        "        # compute tours for baseline\n",
        "        with torch.no_grad():\n",
        "            tour_baseline, _ = model_baseline(data.to(device), deterministic=True)\n",
        "\n",
        "        # get the lengths of the tours\n",
        "        x = x.to(device)\n",
        "        L_train = compute_tour_length(x, tour_train) # size(L_train)=(batch_size)\n",
        "        L_baseline = compute_tour_length(x, tour_baseline) # size(L_baseline)=(batch_size)\n",
        "\n",
        "        # backprop\n",
        "        loss = torch.mean((L_train - L_baseline) * sumLogProbOfActions )\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    time_one_epoch = time.time()-start\n",
        "    time_tot = time.time()-start_training_time + tot_time_ckpt\n",
        "\n",
        "\n",
        "    # -----------------\n",
        "    # Evaluate train model and baseline on 10k random TSP instances\n",
        "    # -----------------\n",
        "    model_train.eval()\n",
        "    mean_tour_length_train = 0\n",
        "    mean_tour_length_baseline = 0\n",
        "\n",
        "    for step in range(0, args.nb_batch_eval):\n",
        "        # generate a batch of random tsp instances\n",
        "        x = torch.rand(args.batch_size, args.nb_nodes, args.dim_input_nodes)\n",
        "\n",
        "        # generate topological features\n",
        "        # new_f = ...\n",
        "        # data = x # np.concat(x, new_f)\n",
        "        torch.tensor(Parallel(n_jobs=-1)(delayed(calculate_homology)(i) for i in x), dtype=torch.float32)\n",
        "\n",
        "        # compute tour for model and baseline\n",
        "        with torch.no_grad():\n",
        "            tour_train, _ = model_train(data.to(device), deterministic=True)\n",
        "            tour_baseline, _ = model_baseline(data.to(device), deterministic=True)\n",
        "\n",
        "        # get the lengths of the tours\n",
        "        L_train = compute_tour_length(x.to(device), tour_train)\n",
        "        L_baseline = compute_tour_length(x.to(device), tour_baseline)\n",
        "\n",
        "        # L_tr and L_bl are tensors of shape (batch_size,). Compute the mean tour length\n",
        "        mean_tour_length_train += L_train.mean().item()\n",
        "        mean_tour_length_baseline += L_baseline.mean().item()\n",
        "\n",
        "    mean_tour_length_train =  mean_tour_length_train / args.nb_batch_eval\n",
        "    mean_tour_length_baseline =  mean_tour_length_baseline / args.nb_batch_eval\n",
        "\n",
        "    # evaluate train model and baseline and update if train model is better\n",
        "    update_baseline = mean_tour_length_train + args.tol < mean_tour_length_baseline\n",
        "    if update_baseline:\n",
        "        model_baseline.load_state_dict(model_train.state_dict())\n",
        "\n",
        "    # For new baseline compute TSPs for small test set\n",
        "    with torch.no_grad():\n",
        "        data = torch.tensor(Parallel(n_jobs=-1)(delayed(calculate_homology)(i) for i in x_test_tsp), dtype=torch.float32)\n",
        "        tour_baseline, _ = model_baseline(data.to(device), deterministic=True)\n",
        "    mean_tour_length_test = compute_tour_length(x_test_tsp, tour_baseline.to('cpu')).mean().item()\n",
        "\n",
        "    # For checkpoint\n",
        "    plot_performance_train.append([(epoch+1), mean_tour_length_train])\n",
        "    plot_performance_baseline.append([(epoch+1), mean_tour_length_baseline])\n",
        "\n",
        "    # Compute optimality gap\n",
        "    gap_train = mean_tour_length_test / x_test_len - 1.0\n",
        "\n",
        "\n",
        "    # Print and save in txt file\n",
        "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_train: {:.3f}, L_base: {:.3f}, L_test: {:.3f}, gap_train(%): {:.3f}, update: {}'.format(\n",
        "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_train, mean_tour_length_baseline, mean_tour_length_test, 100*gap_train, update_baseline)\n",
        "    print(mystring_min) # Comment if plot display\n",
        "\n",
        "    # all_strings.append(mystring_min) # Uncomment if plot display\n",
        "    # for string in all_strings:\n",
        "    #     print(string)\n",
        "\n",
        "    # Saving checkpoint\n",
        "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'time': time_one_epoch,\n",
        "        'tot_time': time_tot,\n",
        "        'loss': loss.item(),\n",
        "        'TSP_length': [torch.mean(L_train).item(), torch.mean(L_baseline).item(), mean_tour_length_test],\n",
        "        'plot_performance_train': plot_performance_train,\n",
        "        'plot_performance_baseline': plot_performance_baseline,\n",
        "        'mean_tour_length_test': mean_tour_length_test,\n",
        "        'model_baseline': model_baseline.state_dict(),\n",
        "        'model_train': model_train.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txokvM3SAtWG"
      },
      "source": [
        "## Final check on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iB8nLwpUAtWG",
        "outputId": "e47a4d6a-090f-4da4-c85e-13b69616486f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.0433) tensor(2.8830)\n"
          ]
        }
      ],
      "source": [
        "# generate topological features\n",
        "# new_f = ...\n",
        "data = x_test_tsp # np.concat(x_test_tsp, new_f)\n",
        "\n",
        "with torch.no_grad():\n",
        "    data = torch.tensor(Parallel(n_jobs=-1)(delayed(calculate_homology)(i) for i in x_test_tsp), dtype=torch.float32)\n",
        "    tour_baseline, _ = model_baseline(data.to(device), deterministic=True)\n",
        "    print(compute_tour_length(x_test_tsp, tour_baseline.to('cpu')).mean(), x_test_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKUlRitzAtWG"
      },
      "source": [
        "# Visualisation\n",
        "Graphs should be fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJrFAnQLAtWG"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance_matrix\n",
        "\n",
        "\n",
        "idx = 0\n",
        "points = np.array(x_test_tsp[idx].to('cpu'))\n",
        "\n",
        "dist_mtx = distance_matrix(points, points)\n",
        "model_tour = np.array(tour_baseline[idx].to('cpu'))\n",
        "\n",
        "def create_graph(tour, dist_mtx):\n",
        "    mask = np.zeros_like(dist_mtx)\n",
        "\n",
        "    for i in range(-1, len(tour) - 1):\n",
        "        point_a = tour[i]\n",
        "        point_b = tour[i + 1]\n",
        "        mask[point_a, point_b] = 1\n",
        "    return nx.from_numpy_matrix(mask * dist_mtx)\n",
        "\n",
        "G = create_graph(model_tour, dist_mtx)\n",
        "pos = nx.spring_layout(G, seed=47)  # Seed layout for reproducibility\n",
        "nx.draw(G)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5keqqooQAtWH"
      },
      "outputs": [],
      "source": [
        "concorde_tour = TSPSolver.from_data(points[:, 0], points[:, 1], norm='GEO').solve(verbose=False).tour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH8uvHW8AtWH"
      },
      "outputs": [],
      "source": [
        "G = create_graph(concorde_tour, dist_mtx)\n",
        "pos = nx.spring_layout(G, seed=47)  # Seed layout for reproducibility\n",
        "nx.draw(G)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICFuJPpUAtWH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tda_tsp",
      "language": "python",
      "name": "tda_tsp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}