{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioAuditore/TDA-for-Travelling-Salesman/blob/main/train_tsp_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtAoQ1Q7IsBR"
      },
      "source": [
        "## Based on \"The Transformer Network for the Traveling Salesman Problem\"\n",
        "\n",
        "Xavier Bresson, Thomas Laurent, Feb 2021<br>\n",
        "\n",
        "Arxiv : https://arxiv.org/pdf/2103.03012.pdf<br>\n",
        "Talk : https://ipam.wistia.com/medias/0jrweluovs<br>\n",
        "Slides : https://t.co/ySxGiKtQL5<br>\n",
        "\n",
        "This code trains the transformer network by reinforcement learning.<br>\n",
        "Use the beam search code to test the trained network.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MarioAuditore/TDA-for-Travelling-Salesman.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvFWrTkbI3Yu",
        "outputId": "de9229bb-dc00-4572-8610-a4b9ab43d3ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TDA-for-Travelling-Salesman'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 54 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (54/54), 104.14 MiB | 19.24 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/TDA-for-Travelling-Salesman')"
      ],
      "metadata": {
        "id": "LE1NUxEVI5ai"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'pyconcorde @ git+https://github.com/jvkersch/pyconcorde'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noRffj-JI7Sm",
        "outputId": "9e70b3e7-b2c6-4649-ff38-a3f8818674d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyconcorde@ git+https://github.com/jvkersch/pyconcorde\n",
            "  Cloning https://github.com/jvkersch/pyconcorde to /tmp/pip-install-ewtszkhi/pyconcorde_607f84db627d499195be1d0b86fe6290\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jvkersch/pyconcorde /tmp/pip-install-ewtszkhi/pyconcorde_607f84db627d499195be1d0b86fe6290\n",
            "  Resolved https://github.com/jvkersch/pyconcorde to commit 8a6b193b79ebdf8f07e0b0635722b3b4edbc1560\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (1.25.2)\n",
            "Collecting tsplib95 (from pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading tsplib95-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (8.1.7)\n",
            "Collecting Deprecated~=1.2.9 (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting networkx~=2.1 (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate~=0.8.7 (from tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde)\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated~=1.2.9->tsplib95->pyconcorde@ git+https://github.com/jvkersch/pyconcorde) (1.14.1)\n",
            "Building wheels for collected packages: pyconcorde\n",
            "  Building wheel for pyconcorde (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyconcorde: filename=pyconcorde-0.1.0-cp310-cp310-linux_x86_64.whl size=2576441 sha256=15e65e4cc7ad6c12610dc28d9053b0409d5185b066305bb95972dde9717b9c36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ffypkplu/wheels/be/9f/eb/e4f95e06e62f057a045679e4940e536d1b251d1ab4859c6dcc\n",
            "Successfully built pyconcorde\n",
            "Installing collected packages: tabulate, networkx, Deprecated, tsplib95, pyconcorde\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.9.0\n",
            "    Uninstalling tabulate-0.9.0:\n",
            "      Successfully uninstalled tabulate-0.9.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.23.0 requires tabulate>=0.9, but you have tabulate 0.8.10 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 networkx-2.8.8 pyconcorde-0.1.0 tabulate-0.8.10 tsplib95-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oDeisCnTIsBX"
      },
      "outputs": [],
      "source": [
        "# ================\n",
        "# Libs\n",
        "# ================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Models\n",
        "from tsp_transformer.model import TSP_net, compute_tour_length\n",
        "\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "# visualization\n",
        "%matplotlib inline\n",
        "# from IPython.display import set_matplotlib_formats, clear_output\n",
        "# set_matplotlib_formats('png2x','pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from concorde.tsp import TSPSolver # !pip install -e pyconcorde\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3aN7sMjIsBZ",
        "outputId": "a47a0e18-fdce-44e6-bec6-6d5dfa8c9ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Hardware : CPU / GPU(s)\n",
        "###################\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    gpu_id = '0'\n",
        "    device = torch.device(\"mps\")\n",
        "\n",
        "elif torch.cuda.is_available():\n",
        "    gpu_id = '0' # select a single GPU\n",
        "    # gpu_id = '2,3' # select multiple GPUs\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))\n",
        "\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    gpu_id = -1 # select CPU\n",
        "\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTYJcyEGIsBZ",
        "outputId": "402c37ba-b31d-4cbf-c274-50aa9b7fdb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu_id': -1, 'nb_nodes': 10, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 2, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 20, 'batch_size': 128, 'nb_batch_per_epoch': 250, 'nb_batch_eval': 100, 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n"
          ]
        }
      ],
      "source": [
        "# ================\n",
        "# Hyper-parameters\n",
        "# ================\n",
        "\n",
        "class DotDict(dict):\n",
        "    def __init__(self, **kwds):\n",
        "        self.update(kwds)\n",
        "        self.__dict__ = self\n",
        "\n",
        "args = DotDict()\n",
        "args.gpu_id = gpu_id\n",
        "\n",
        "# TSP problem number of nodes\n",
        "args.nb_nodes = 10 # TSP20\n",
        "# args.nb_nodes = 50 # TSP50\n",
        "# args.nb_nodes = 100 # TSP100\n",
        "\n",
        "# Transformer parameters\n",
        "args.dim_emb = 128 # dimension of embeddings in transformer\n",
        "args.dim_ff = 512 # dimension of feed forward layers\n",
        "args.dim_input_nodes = 2 # dimension of input features\n",
        "args.nb_layers_encoder = 6\n",
        "args.nb_layers_decoder = 2\n",
        "args.nb_heads = 8\n",
        "\n",
        "#\n",
        "args.nb_epochs = 20 # number of epochs\n",
        "args.batch_size = 128 # batch size\n",
        "args.nb_batch_per_epoch = 250 # number of batches to generate on each epoch for training\n",
        "args.nb_batch_eval = 100 # number of batches to generate on each epoch for evaluation\n",
        "args.lr = 1e-4 # optimiser lr\n",
        "args.tol = 1e-3 # model should perform better w.r.t tolerance to be updated\n",
        "args.batchnorm = True  # if batchnorm=True  than batch norm is used\n",
        "# args.batchnorm = False # if batchnorm=False than layer norm is used\n",
        "args.max_len_PE = 1000\n",
        "\n",
        "print(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFreouSJIsBa"
      },
      "source": [
        "# Training\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adFq4P8HIsBa",
        "outputId": "633ba8cf-19e0-4f89-a46b-5b4afa95c838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gpu_id': -1, 'nb_nodes': 10, 'dim_emb': 128, 'dim_ff': 512, 'dim_input_nodes': 2, 'nb_layers_encoder': 6, 'nb_layers_decoder': 2, 'nb_heads': 8, 'nb_epochs': 20, 'batch_size': 128, 'nb_batch_per_epoch': 250, 'nb_batch_eval': 100, 'lr': 0.0001, 'tol': 0.001, 'batchnorm': True, 'max_len_PE': 1000}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Instantiate a training network and a baseline network\n",
        "###################\n",
        "try:\n",
        "    del model_train # remove existing model\n",
        "    del model_baseline # remove existing model\n",
        "except:\n",
        "    pass\n",
        "\n",
        "model_train = TSP_net(args.dim_input_nodes,\n",
        "                      args.dim_emb,\n",
        "                      args.dim_ff,\n",
        "                      args.nb_layers_encoder,\n",
        "                      args.nb_layers_decoder,\n",
        "                      args.nb_heads,\n",
        "                      args.max_len_PE,\n",
        "                      batchnorm=args.batchnorm)\n",
        "\n",
        "model_baseline = TSP_net(args.dim_input_nodes,\n",
        "                         args.dim_emb,\n",
        "                         args.dim_ff,\n",
        "                         args.nb_layers_encoder,\n",
        "                         args.nb_layers_decoder,\n",
        "                         args.nb_heads,\n",
        "                         args.max_len_PE,\n",
        "                         batchnorm=args.batchnorm)\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(torch.cuda.device_count() + \" cuda devices found, doing parallel training.\")\n",
        "    model_train = nn.DataParallel(model_train)\n",
        "    model_baseline = nn.DataParallel(model_baseline)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_train.parameters(), lr = args.lr)\n",
        "\n",
        "model_train = model_train.to(device)\n",
        "model_baseline = model_baseline.to(device)\n",
        "model_baseline.eval()\n",
        "\n",
        "print(args); print('')\n",
        "\n",
        "# Logs\n",
        "os.system(\"mkdir logs\")\n",
        "time_stamp=datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n",
        "file_name = 'logs'+'/'+time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id) + \".txt\"\n",
        "file = open(file_name,\"w\",1)\n",
        "file.write(time_stamp+'\\n\\n')\n",
        "for arg in vars(args):\n",
        "    file.write(arg)\n",
        "    hyper_param_val=\"={}\".format(getattr(args, arg))\n",
        "    file.write(hyper_param_val)\n",
        "    file.write('\\n')\n",
        "file.write('\\n\\n')\n",
        "plot_performance_train = []\n",
        "plot_performance_baseline = []\n",
        "all_strings = []\n",
        "epoch_ckpt = 0\n",
        "tot_time_ckpt = 0\n",
        "\n",
        "\n",
        "# # Uncomment these lines to re-start training with saved checkpoint\n",
        "# ====================================================================\n",
        "# checkpoint_file = \"checkpoint/checkpoint_21-03-01--17-25-00-n50-gpu0.pkl\"\n",
        "# checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "# epoch_ckpt = checkpoint['epoch'] + 1\n",
        "# tot_time_ckpt = checkpoint['tot_time']\n",
        "# plot_performance_train = checkpoint['plot_performance_train']\n",
        "# plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
        "# model_baseline.load_state_dict(checkpoint['model_baseline'])\n",
        "# model_train.load_state_dict(checkpoint['model_train'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "# print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
        "# del checkpoint\n",
        "# ====================================================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln3f7CkpIsBb"
      },
      "source": [
        "## Test nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuMsm3NxIsBb",
        "outputId": "ab1ebd20-0e0e-4756-f549-e8ccb0480ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb of nodes : 10\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Small test set for quick algorithm comparison\n",
        "# Note : this can be removed\n",
        "###################\n",
        "\n",
        "save_1000tsp = False\n",
        "\n",
        "test_size = 10\n",
        "\n",
        "if save_1000tsp:\n",
        "    x = torch.rand(test_size, args.nb_nodes, args.dim_input_nodes, device='cpu')\n",
        "    print(x.size(),x[0])\n",
        "    data_dir = os.path.join(\"data\")\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    if args.nb_nodes==20 : torch.save({ 'x': x, }, '{}.pkl'.format(data_dir + \"/1000tsp20\"))\n",
        "    if args.nb_nodes==50 : torch.save({ 'x': x, }, '{}.pkl'.format(data_dir + \"/1000tsp50\"))\n",
        "    if args.nb_nodes==100 : torch.save({ 'x': x, }, '{}.pkl'.format(data_dir + \"/1000tsp100\"))\n",
        "\n",
        "checkpoint = None\n",
        "\n",
        "if args.nb_nodes==20 : checkpoint = torch.load(\"data/1000tsp20.pkl\")\n",
        "if args.nb_nodes==50 : checkpoint = torch.load(\"data/1000tsp50.pkl\")\n",
        "if args.nb_nodes==100 : checkpoint = torch.load(\"data/1000tsp100.pkl\")\n",
        "\n",
        "if checkpoint is not None:\n",
        "    x_test_tsp = checkpoint['x'].to(device)\n",
        "    n = x_test_tsp.size(1)\n",
        "    print('nb of nodes :',n)\n",
        "else:\n",
        "    x_test_tsp = torch.rand(test_size, args.nb_nodes, args.dim_input_nodes, device='cpu')\n",
        "    n = x_test_tsp.size(1)\n",
        "    print('nb of nodes :',n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAjl1QlcIsBb"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "blglcEPMIsBb",
        "outputId": "f293639d-a5ff-4c47-b47e-503c76617cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:47<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-af3c71639990>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# compute tours for baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtour_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# get the lengths of the tours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TDA-for-Travelling-Salesman/tsp_transformer/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, deterministic)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# encoder layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mh_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# size(h)=(bsz, nb_nodes+1, dim_emb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# list that will contain Long tensors of shape (bsz,) that gives the idx of the cities chosen at time t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TDA-for-Travelling-Salesman/tsp_transformer/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_rc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;31m# size(h)=(nb_nodes, bsz, dim_emb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# size(h)=(bsz, dim_emb, nb_nodes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# size(h)=(bsz, dim_emb, nb_nodes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# size(h)=(nb_nodes, bsz, dim_emb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==================\n",
        "# Main training loop\n",
        "# ==================\n",
        "\n",
        "\n",
        "start_training_time = time.time()\n",
        "\n",
        "for epoch in tqdm(range(0, args.nb_epochs)):\n",
        "\n",
        "    # re-start training with saved checkpoint\n",
        "    # epoch += epoch_ckpt\n",
        "\n",
        "    # -------------------------\n",
        "    # Train model for one epoch\n",
        "    # -------------------------\n",
        "    start = time.time()\n",
        "    model_train.train()\n",
        "\n",
        "    for step in range(1, args.nb_batch_per_epoch + 1):\n",
        "\n",
        "        # generate a batch of random TSP instances\n",
        "        x = torch.rand(args.batch_size, args.nb_nodes, args.dim_input_nodes, device=device) # size(x)=(batch_size, nb_nodes, dim_input_nodes)\n",
        "\n",
        "        # generate new features\n",
        "        # new_f = ...\n",
        "        data = x # np.concat(x, new_f)\n",
        "\n",
        "        # compute tours for model\n",
        "        tour_train, sumLogProbOfActions = model_train(data, deterministic=False) # size(tour_train)=(batch_size, nb_nodes), size(sumLogProbOfActions)=(batch_size)\n",
        "\n",
        "        # compute tours for baseline\n",
        "        with torch.no_grad():\n",
        "            tour_baseline, _ = model_baseline(data, deterministic=True)\n",
        "\n",
        "        # get the lengths of the tours\n",
        "        L_train = compute_tour_length(x, tour_train) # size(L_train)=(batch_size)\n",
        "        L_baseline = compute_tour_length(x, tour_baseline) # size(L_baseline)=(batch_size)\n",
        "\n",
        "        # backprop\n",
        "        loss = torch.mean((L_train - L_baseline) * sumLogProbOfActions )\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    time_one_epoch = time.time()-start\n",
        "    time_tot = time.time()-start_training_time + tot_time_ckpt\n",
        "\n",
        "\n",
        "    # -----------------\n",
        "    # Evaluate train model and baseline on 10k random TSP instances\n",
        "    # -----------------\n",
        "    model_train.eval()\n",
        "    mean_tour_length_train = 0\n",
        "    mean_tour_length_baseline = 0\n",
        "\n",
        "    for step in range(0, args.nb_batch_eval):\n",
        "        # generate a batch of random tsp instances\n",
        "        x = torch.rand(args.batch_size, args.nb_nodes, args.dim_input_nodes, device=device)\n",
        "\n",
        "        # generate new features\n",
        "        # new_f = ...\n",
        "        data = x # np.concat(x, new_f)\n",
        "\n",
        "        # compute tour for model and baseline\n",
        "        with torch.no_grad():\n",
        "            tour_train, _ = model_train(data, deterministic=True)\n",
        "            tour_baseline, _ = model_baseline(data, deterministic=True)\n",
        "\n",
        "        # get the lengths of the tours\n",
        "        L_train = compute_tour_length(x, tour_train)\n",
        "        L_baseline = compute_tour_length(x, tour_baseline)\n",
        "\n",
        "        # L_tr and L_bl are tensors of shape (batch_size,). Compute the mean tour length\n",
        "        mean_tour_length_train += L_train.mean().item()\n",
        "        mean_tour_length_baseline += L_baseline.mean().item()\n",
        "\n",
        "    mean_tour_length_train =  mean_tour_length_train/ args.nb_batch_eval\n",
        "    mean_tour_length_baseline =  mean_tour_length_baseline/ args.nb_batch_eval\n",
        "\n",
        "    # evaluate train model and baseline and update if train model is better\n",
        "    update_baseline = mean_tour_length_train + args.tol < mean_tour_length_baseline\n",
        "    if update_baseline:\n",
        "        model_baseline.load_state_dict(model_train.state_dict())\n",
        "\n",
        "    # For new baseline compute TSPs for small test set\n",
        "    with torch.no_grad():\n",
        "        tour_baseline, _ = model_baseline(x_test_tsp.to(device), deterministic=True)\n",
        "    mean_tour_length_test = compute_tour_length(x_test_tsp, tour_baseline.to('cpu')).mean().item()\n",
        "\n",
        "    # For checkpoint\n",
        "    plot_performance_train.append([(epoch+1), mean_tour_length_train])\n",
        "    plot_performance_baseline.append([(epoch+1), mean_tour_length_baseline])\n",
        "\n",
        "    # Compute optimality gap\n",
        "    if args.nb_nodes==50: gap_train = mean_tour_length_train/5.692 - 1.0\n",
        "    elif args.nb_nodes==100: gap_train = mean_tour_length_train/7.765 - 1.0\n",
        "    else: gap_train = -1.0\n",
        "\n",
        "    # # Print and save in txt file\n",
        "    # mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_train: {:.3f}, L_base: {:.3f}, L_test: {:.3f}, gap_train(%): {:.3f}, update: {}'.format(\n",
        "    #     epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_train, mean_tour_length_baseline, mean_tour_length_test, 100*gap_train, update_baseline)\n",
        "    # print(mystring_min) # Comment if plot display\n",
        "    # file.write(mystring_min+'\\n')\n",
        "\n",
        "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f} min, tot time: {:.3f}day, L_train: {:.3f}, L_base: {:.3f}, L_test: {:.3f}, gap_train(%): {:.3f}, update: {}'.format(\n",
        "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_train, mean_tour_length_baseline, mean_tour_length_test, 100*gap_train, update_baseline)\n",
        "    print(mystring_min) # Comment if plot display\n",
        "\n",
        "    # all_strings.append(mystring_min) # Uncomment if plot display\n",
        "    # for string in all_strings:\n",
        "    #     print(string)\n",
        "\n",
        "    # Saving checkpoint\n",
        "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'time': time_one_epoch,\n",
        "        'tot_time': time_tot,\n",
        "        'loss': loss.item(),\n",
        "        'TSP_length': [torch.mean(L_train).item(), torch.mean(L_baseline).item(), mean_tour_length_test],\n",
        "        'plot_performance_train': plot_performance_train,\n",
        "        'plot_performance_baseline': plot_performance_baseline,\n",
        "        'mean_tour_length_test': mean_tour_length_test,\n",
        "        'model_baseline': model_baseline.state_dict(),\n",
        "        'model_train': model_train.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        }, '{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(args.nb_nodes) + \"-gpu{}\".format(args.gpu_id)))\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt7zX2FgIsBc"
      },
      "source": [
        "## Final check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPy417LMIsBc",
        "outputId": "bcd69063-1b38-418c-c13c-a17486898217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.2266)\n"
          ]
        }
      ],
      "source": [
        "# generate a batch of random TSP instances\n",
        "x = torch.rand(args.batch_size, args.nb_nodes, args.dim_input_nodes, device=device) # size(x)=(batch_size, nb_nodes, dim_input_nodes)\n",
        "\n",
        "# generate new features\n",
        "# new_f = ...\n",
        "data = x # np.concat(x, new_f)\n",
        "\n",
        "with torch.no_grad():\n",
        "    tour_baseline, _ = model_baseline(data, deterministic=True)\n",
        "    print(compute_tour_length(x, tour_train).mean())\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "q0m1WiTMIsBc"
      },
      "source": [
        "# Visualisation (BROKEN)\n",
        "## Checkpoint\n",
        "Here you can load checkpoints of models from original github trained on TSPs of different sizes. Don't use this code if you want to plot the model from above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhANgx2AIsBc"
      },
      "outputs": [],
      "source": [
        "# ===============\n",
        "# Load checkpoint\n",
        "# ===============\n",
        "\n",
        "load_checkpoint = False # change to True if you need\n",
        "\n",
        "if load_checkpoint:\n",
        "    checkpoint_file = \"checkpoint/checkpoint_21-03-01--17-25-00-n50-gpu0.pkl\"\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "\n",
        "    epoch_ckpt = checkpoint['epoch'] + 1\n",
        "    tot_time_ckpt = checkpoint['tot_time']\n",
        "\n",
        "    plot_performance_train = checkpoint['plot_performance_train']\n",
        "    plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
        "\n",
        "    model_baseline.load_state_dict(checkpoint['model_baseline'])\n",
        "\n",
        "    print('Load checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
        "    del checkpoint\n",
        "\n",
        "    mystring_min = 'Epoch: {:d}, tot_time_ckpt: {:.3f}day, L_train: {:.3f}, L_base: {:.3f}\\n'.format(\n",
        "        epoch_ckpt, tot_time_ckpt/3660/24, plot_performance_train[-1][1], plot_performance_baseline[-1][1])\n",
        "    print(mystring_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1cGYrMnIsBd"
      },
      "source": [
        "## Beam search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5XcgmILIsBd"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# Hyper-parameter for beam search\n",
        "# ===============================\n",
        "\n",
        "# experiment n50\n",
        "# B = 1; args.bsz = 10000; greedy = True; beamsearch = False # greedy\n",
        "# B = 100; args.bsz = 250; greedy = False; beamsearch = True\n",
        "# B = 1000; args.bsz = 25; greedy = False; beamsearch = True\n",
        "B = 2500; args.bsz = 10; greedy = False; beamsearch = True\n",
        "args.nb_batch_eval = (10000+args.bsz-1)// args.bsz\n",
        "print('nb_nodes: {}, bsz: {}, B: {}, nb_batch_eval: {}, tot TSPs: {}\\n'.format(args.nb_nodes, args.bsz, B, args.nb_batch_eval, args.nb_batch_eval* args.bsz))\n",
        "\n",
        "# # experiment n100\n",
        "# args.nb_nodes = 100\n",
        "# B = 1; args.bsz = 5000; greedy = True; beamsearch = False # greedy\n",
        "# B = 1000; args.bsz = 10; greedy = False; beamsearch = True\n",
        "# args.nb_batch_eval = (10000+args.bsz-1)// args.bsz\n",
        "# print('nb_nodes: {}, bsz: {}, B: {}, nb_batch_eval: {}, tot TSPs: {}\\n'.format(args.nb_nodes, args.bsz, B, args.nb_batch_eval, args.nb_batch_eval* args.bsz))\n",
        "\n",
        "\n",
        "\n",
        "# ========\n",
        "# Test set\n",
        "# ========\n",
        "\n",
        "load_points = False\n",
        "\n",
        "if load_points:\n",
        "    if args.nb_nodes == 50:\n",
        "        x_10k = torch.load('data/10k_TSP50.pt').to(device)\n",
        "        x_10k_len = torch.load('data/10k_TSP50_len.pt').to(device)\n",
        "        L_concorde = x_10k_len.mean().item()\n",
        "    if args.nb_nodes == 100:\n",
        "        x_10k = torch.load('data/10k_TSP100.pt').to(device)\n",
        "        x_10k_len = torch.load('data/10k_TSP100_len.pt').to(device)\n",
        "        L_concorde = x_10k_len.mean().item()\n",
        "else:\n",
        "    test_size = 50\n",
        "    x_10k = torch.rand(test_size, args.nb_nodes, args.dim_input_nodes, device='cpu')\n",
        "\n",
        "nb_TSPs = args.nb_batch_eval* args.bsz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP8jpTYWIsBd"
      },
      "outputs": [],
      "source": [
        "x_10k = torch.load('data/10k_TSP50.pt').to(device)\n",
        "x_10k_len = torch.load('data/10k_TSP50_len.pt').to(device)\n",
        "L_concorde = x_10k_len.mean().item()\n",
        "\n",
        "x_10k_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYg6-hgUIsBd"
      },
      "outputs": [],
      "source": [
        "# ===============\n",
        "# Run beam search\n",
        "# ===============\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "mean_tour_length_greedy = 0\n",
        "mean_tour_length_beamsearch = 0\n",
        "mean_scores_greedy = 0\n",
        "mean_scores_beamsearch = 0\n",
        "gap_greedy = 0\n",
        "gap_beamsearch = 0\n",
        "\n",
        "for step in range(0,args.nb_batch_eval):\n",
        "    print('batch index: {}, tot_time: {:.3f}min'.format(step, (time.time()-start)/60))\n",
        "\n",
        "    # extract a batch of test tsp instances\n",
        "    x = x_10k[step*args.bsz:(step+1)*args.bsz,:,:]\n",
        "    x_len_concorde = x_10k_len[step*args.bsz:(step+1)*args.bsz]\n",
        "\n",
        "    # compute tour for model and baseline\n",
        "    with torch.no_grad():\n",
        "        tours_greedy, tours_beamsearch, scores_greedy, scores_beamsearch = model_baseline(x, B, greedy, beamsearch)\n",
        "\n",
        "        # greedy\n",
        "        if greedy:\n",
        "            L_greedy = compute_tour_length(x, tours_greedy)\n",
        "            mean_tour_length_greedy += L_greedy.mean().item()\n",
        "            mean_scores_greedy += scores_greedy.mean().item()\n",
        "            x_len_greedy = L_greedy\n",
        "            gap_greedy += (x_len_greedy/ x_len_concorde - 1.0).sum()\n",
        "\n",
        "        # beamsearch\n",
        "        if beamsearch:\n",
        "            tours_beamsearch = tours_beamsearch.view(args.bsz*B, args.nb_nodes)\n",
        "            x = x.repeat_interleave(B,dim=0)\n",
        "            L_beamsearch = compute_tour_length(x, tours_beamsearch)\n",
        "            tours_beamsearch = tours_beamsearch.view(args.bsz, B, args.nb_nodes)\n",
        "            L_beamsearch = L_beamsearch.view(args.bsz, B)\n",
        "            L_beamsearch_tmp = L_beamsearch\n",
        "            L_beamsearch, idx_min = L_beamsearch.min(dim=1)\n",
        "            mean_tour_length_beamsearch += L_beamsearch.mean().item()\n",
        "            mean_scores_beamsearch += scores_beamsearch.mean().item()\n",
        "            x_len_beamsearch = L_beamsearch\n",
        "            gap_beamsearch += (x_len_beamsearch/ x_len_concorde - 1.0).sum()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache() # free GPU reserved memory\n",
        "if greedy:\n",
        "    mean_tour_length_greedy =  mean_tour_length_greedy/ args.nb_batch_eval\n",
        "    mean_scores_greedy =  mean_scores_greedy/ args.nb_batch_eval\n",
        "    gap_greedy = (gap_greedy/ nb_TSPs).item()\n",
        "\n",
        "if beamsearch:\n",
        "    mean_tour_length_beamsearch =  mean_tour_length_beamsearch/ args.nb_batch_eval\n",
        "    mean_scores_beamsearch =  mean_scores_beamsearch/ args.nb_batch_eval\n",
        "    gap_beamsearch /= nb_TSPs\n",
        "tot_time = time.time()-start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS6GzZh7IsBd"
      },
      "outputs": [],
      "source": [
        "# =================\n",
        "# Write result file\n",
        "# =================\n",
        "\n",
        "nb_TSPs = args.nb_batch_eval* args.bsz\n",
        "file_name = \"beamsearch-nb_nodes{}\".format(args.nb_nodes) + \"-nb_TSPs{}\".format(nb_TSPs) + \"-B{}\".format(B) + \".txt\"\n",
        "file = open(file_name,\"w\",1)\n",
        "mystring = '\\nnb_nodes: {:d}, nb_TSPs: {:d}, B: {:d}, L_greedy: {:.6f}, L_concorde: {:.5f}, L_beamsearch: {:.5f}, \\\n",
        "gap_greedy(%): {:.5f}, gap_beamsearch(%): {:.5f}, scores_greedy: {:.5f}, scores_beamsearch: {:.5f}, tot_time: {:.4f}min, \\\n",
        "tot_time: {:.3f}hr, mean_time: {:.3f}sec'.format(args.nb_nodes, nb_TSPs, B, mean_tour_length_greedy, L_concorde, \\\n",
        "                                 mean_tour_length_beamsearch, 100*gap_greedy, 100*gap_beamsearch, mean_scores_greedy, \\\n",
        "                                 mean_scores_beamsearch, tot_time/60, tot_time/3600, tot_time/nb_TSPs)\n",
        "print(mystring)\n",
        "file.write(mystring)\n",
        "file.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tda_tsp",
      "language": "python",
      "name": "tda_tsp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q0m1WiTMIsBc"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}